import 'dart:async';
import 'dart:io';
import 'dart:convert';

import 'package:flutter/material.dart';
import 'package:flutter_sound/public/flutter_sound_recorder.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:path_provider/path_provider.dart';
import 'package:permission_handler/permission_handler.dart';

import 'ChatApiService.dart';
import 'Message.dart';
import 'storage_service.dart';
import 'LoginPage.dart';
import 'auth_service.dart';

class VoiceChatPage extends StatefulWidget {
  const VoiceChatPage({Key? key}) : super(key: key);

  @override
  State<VoiceChatPage> createState() => _VoiceChatPageState();
}

class _VoiceChatPageState extends State<VoiceChatPage> with TickerProviderStateMixin {
  final List<Message> _messages = [];
  final TextEditingController _textController = TextEditingController();
  final ScrollController _scrollController = ScrollController();

  late FlutterSoundRecorder _recorder;
  late FlutterSoundPlayer _player;
  bool _isRecording = false;
  bool _isListening = false;
  bool _isTyping = false;
  bool _recorderInitialized = false;
  bool _playerInitialized = false;
  bool _isPlaying = false;
  String? _currentlyPlayingMessageId;

  late AnimationController _pulseController;
  late AnimationController _waveController;
  late Animation<double> _pulseAnimation;

  @override
  void initState() {
    super.initState();

    // Animation pour le bouton vocal
    _pulseController = AnimationController(
      duration: const Duration(milliseconds: 1500),
      vsync: this,
    );

    _pulseAnimation = Tween<double>(begin: 1.0, end: 1.2).animate(
      CurvedAnimation(parent: _pulseController, curve: Curves.easeInOut),
    );

    // Animation pour les ondes sonores
    _waveController = AnimationController(
      duration: const Duration(milliseconds: 800),
      vsync: this,
    );

    // üîπ Initialiser le recorder et le player
    _recorder = FlutterSoundRecorder();
    _player = FlutterSoundPlayer();

    // Charger les messages sauvegard√©s
    _loadMessages();
  }

  // Charger les messages depuis le stockage local
  Future<void> _loadMessages() async {
    try {
      final savedMessages = await StorageService.loadMessages();
      if (savedMessages.isNotEmpty) {
        setState(() {
          _messages.clear();
          for (var msgJson in savedMessages) {
            _messages.add(Message.fromJson(msgJson));
          }
        });
        // Faire d√©filer vers le bas apr√®s le chargement
        WidgetsBinding.instance.addPostFrameCallback((_) {
          _scrollToBottom();
        });
        print('‚úÖ [VoiceChatPage] ${_messages.length} messages charg√©s');
      } else {
        // Si aucun message sauvegard√©, ajouter le message d'accueil
        setState(() {
          _messages.add(Message(
            text: "Bonjour ! Je suis votre assistant financier. Comment puis-je vous aider aujourd'hui ?",
            isUser: false,
            timestamp: DateTime.now(),
          ));
        });
        await _saveMessages();
      }
    } catch (e) {
      print('‚ùå [VoiceChatPage] Erreur lors du chargement des messages: $e');
      // En cas d'erreur, ajouter le message d'accueil
      setState(() {
        _messages.add(Message(
          text: "Bonjour ! Je suis votre assistant financier. Comment puis-je vous aider aujourd'hui ?",
          isUser: false,
          timestamp: DateTime.now(),
        ));
      });
      await _saveMessages();
    }
  }

  // Sauvegarder les messages dans le stockage local
  Future<void> _saveMessages() async {
    try {
      final messagesJson = _messages.map((msg) => msg.toJson()).toList();
      await StorageService.saveMessages(messagesJson);
      print('‚úÖ [VoiceChatPage] ${_messages.length} messages sauvegard√©s');
    } catch (e) {
      print('‚ùå [VoiceChatPage] Erreur lors de la sauvegarde des messages: $e');
    }
  }

  // M√©thode de d√©connexion
  Future<void> _logout() async {
    // Afficher une bo√Æte de dialogue de confirmation
    final confirm = await showDialog<bool>(
      context: context,
      builder: (BuildContext context) {
        return AlertDialog(
          title: const Text('D√©connexion'),
          content: const Text('√ätes-vous s√ªr de vouloir vous d√©connecter ?'),
          actions: [
            TextButton(
              onPressed: () => Navigator.of(context).pop(false),
              child: const Text('Annuler'),
            ),
            TextButton(
              onPressed: () => Navigator.of(context).pop(true),
              child: const Text('D√©connexion'),
            ),
          ],
        );
      },
    );

    if (confirm == true) {
      // Effacer les donn√©es d'authentification et les messages
      await StorageService.clearAuth();
      await StorageService.clearMessages();
      
      // Rediriger vers la page de login
      if (mounted) {
        Navigator.pushAndRemoveUntil(
          context,
          MaterialPageRoute(builder: (context) => const LoginPage()),
          (route) => false, // Supprimer toutes les routes pr√©c√©dentes
        );
      }
    }
  }

  @override
  void dispose() async {
    _textController.dispose();
    _scrollController.dispose();
    _pulseController.dispose();
    _waveController.dispose();
    if (_recorderInitialized) {
      await _recorder.closeRecorder();
    }
    if (_playerInitialized) {
      await _player.closePlayer();
    }
    super.dispose();
  }

  void _scrollToBottom() {
    if (_scrollController.hasClients) {
      Timer(const Duration(milliseconds: 300), () {
        _scrollController.animateTo(
          _scrollController.position.maxScrollExtent,
          duration: const Duration(milliseconds: 300),
          curve: Curves.easeOut,
        );
      });
    }
  }


  void _handleStopRecordingAndSend() async {
    // Arr√™ter les animations
    _pulseController.stop();
    _waveController.stop();

    // V√©rifier qu'un enregistrement √©tait en cours
    if (!_isRecording || !_recorderInitialized) {
      if (mounted) {
        setState(() {
          _isRecording = false;
          _isListening = false;
        });
      }
      return;
    }

    try {
      File audioFile = await stopRecording();
      
      // Mettre √† jour l'√©tat apr√®s avoir arr√™t√© l'enregistrement
      if (!mounted) return;
      
      setState(() {
        _isRecording = false;
        _isListening = false;
      });
      
      // Attendre un peu pour que l'UI se mette √† jour
      await Future.delayed(const Duration(milliseconds: 100));
      
      if (!mounted) return;
      
      // V√©rifier que le fichier existe et n'est pas vide
      if (!await audioFile.exists()) {
        throw Exception('Le fichier audio n\'existe pas');
      }

      // V√©rifier la taille du fichier
      final fileSize = await audioFile.length();
      if (fileSize == 0) {
        throw Exception('Le fichier audio est vide (0 bytes). Veuillez r√©essayer.');
      }

      // Affiche un message audio de l'utilisateur avec le chemin du fichier
      if (!mounted) return;
      
      setState(() {
        _messages.add(Message(
          text: "üé§ Audio",
          isUser: true,
          timestamp: DateTime.now(),
          isAudio: true,
          audioFilePath: audioFile.path, // Sauvegarder le chemin pour pouvoir le r√©√©couter
        ));
      });
      
      _saveMessages();
      _scrollToBottom();

      // Appel au backend (le userId est extrait du token c√¥t√© backend)
      // Utiliser la m√™me base URL que dans auth_service (sans /api/auth)
      final baseUrl = AuthService.baseUrl.replaceAll('/api/auth', '');
      print('üîó [VoiceChatPage] Base URL: $baseUrl');
      print('üìÅ [VoiceChatPage] Fichier audio: ${audioFile.path} (${await audioFile.length()} bytes)');
      
      final response = await ChatApiService(baseUrl: baseUrl)
          .sendAudioQuestion(audioFile);
      
      print('‚úÖ [VoiceChatPage] R√©ponse re√ßue du backend: $response');

      if (!mounted) return;

      // Extraire l'audio Base64 de la r√©ponse
      final audioBase64 = response['audioBase64'] as String?;
      final answerText = response['answerText'] as String? ?? 'R√©ponse non disponible';

      setState(() {
        // Ajouter la r√©ponse audio de l'assistant
        _messages.add(Message(
          text: "üéµ R√©ponse audio",
          isUser: false,
          timestamp: DateTime.now(),
          isAudio: true,
          audioBase64: audioBase64,
        ));
      });

      _saveMessages();
      if (mounted) {
        _scrollToBottom();
        // Jouer automatiquement l'audio de la r√©ponse
        if (audioBase64 != null && audioBase64.isNotEmpty) {
          _playAudioFromBase64(audioBase64, _messages.length - 1);
        }
      }

    } catch (e, stackTrace) {
      // Mettre √† jour l'√©tat en cas d'erreur (uniquement si le widget est toujours mont√©)
      print('‚ùå [VoiceChatPage] Erreur lors de l\'envoi: $e');
      print('üìö [VoiceChatPage] Stack trace: $stackTrace');
      
      if (!mounted) return;
      
      // Extraire le message d'erreur
      String errorMessage = "Erreur lors de l'envoi de l'audio : $e";
      bool shouldLogout = false;
      
      if (e.toString().contains('403') || e.toString().contains('401')) {
        errorMessage = "Erreur d'authentification. Veuillez vous reconnecter.";
        shouldLogout = true;
      } else if (e.toString().contains('vide') || e.toString().contains('empty')) {
        errorMessage = "Le fichier audio est vide. Veuillez parler plus longtemps et r√©essayer.";
      } else if (e.toString().contains('Connection') || e.toString().contains('timeout') || e.toString().contains('Timeout')) {
        errorMessage = "Erreur de connexion ou timeout. V√©rifiez votre connexion internet et r√©essayez.";
      }
      
      // Nettoyer l'authentification si n√©cessaire
      if (shouldLogout) {
        await StorageService.clearAuth();
      }
      
      // Utiliser WidgetsBinding.instance.addPostFrameCallback pour √©viter les probl√®mes de contexte
      WidgetsBinding.instance.addPostFrameCallback((_) {
        if (!mounted) return;
        setState(() {
          _isRecording = false;
          _isListening = false;
          
          // Ne rien supprimer, garder l'audio de l'utilisateur

          _messages.add(Message(
            text: errorMessage,
            isUser: false,
            timestamp: DateTime.now(),
          ));
        });
        _saveMessages();
        
        if (mounted && shouldLogout) {
          Navigator.pushReplacement(
            context,
            MaterialPageRoute(builder: (context) => const LoginPage()),
          );
        }
      });
    }
  }


  void _handleTextMessage() async {
    final text = _textController.text.trim();
    if (text.isEmpty) return;

    // Ajouter le message de l'utilisateur
    setState(() {
      _messages.add(Message(
        text: text,
        isUser: true,
        timestamp: DateTime.now(),
        isAudio: false,
      ));
    });

    _saveMessages();
    _textController.clear();
    _scrollToBottom();

    try {
      // Envoyer la question texte au backend
      final baseUrl = AuthService.baseUrl.replaceAll('/api/auth', '');
      print('üìù [VoiceChatPage] Envoi de la question texte: $text');
      
      final response = await ChatApiService(baseUrl: baseUrl)
          .sendTextQuestion(text);
      
      print('‚úÖ [VoiceChatPage] R√©ponse texte re√ßue du backend: $response');

      if (!mounted) return;

      // Extraire la r√©ponse texte
      final answerText = response['answerText'] as String? ?? 'R√©ponse non disponible';

      setState(() {
        // Ajouter la r√©ponse texte de l'assistant (pas audio)
        _messages.add(Message(
          text: answerText,
          isUser: false,
          timestamp: DateTime.now(),
          isAudio: false, // R√©ponse texte, pas audio
        ));
      });

      _saveMessages();
      if (mounted) {
        _scrollToBottom();
      }

    } catch (e, stackTrace) {
      print('‚ùå [VoiceChatPage] Erreur lors de l\'envoi du texte: $e');
      print('üìö [VoiceChatPage] Stack trace: $stackTrace');
      
      if (!mounted) return;
      
      // Extraire le message d'erreur
      String errorMessage = "Erreur lors de l'envoi du message : $e";
      bool shouldLogout = false;
      
      if (e.toString().contains('403') || e.toString().contains('401')) {
        errorMessage = "Erreur d'authentification. Veuillez vous reconnecter.";
        shouldLogout = true;
      } else if (e.toString().contains('Connection') || e.toString().contains('timeout') || e.toString().contains('Timeout')) {
        errorMessage = "Erreur de connexion ou timeout. V√©rifiez votre connexion internet et r√©essayez.";
      }
      
      // Nettoyer l'authentification si n√©cessaire
      if (shouldLogout) {
        await StorageService.clearAuth();
      }
      
      // Utiliser WidgetsBinding.instance.addPostFrameCallback pour √©viter les probl√®mes de contexte
      WidgetsBinding.instance.addPostFrameCallback((_) {
        if (!mounted) return;
        setState(() {
          _messages.add(Message(
            text: errorMessage,
            isUser: false,
            timestamp: DateTime.now(),
            isAudio: false,
          ));
        });
        _saveMessages();
        
        if (mounted && shouldLogout) {
          Navigator.pushReplacement(
            context,
            MaterialPageRoute(builder: (context) => const LoginPage()),
          );
        }
      });
    }
  }

  Future<bool> requestPermissions() async {
    try {
      // Demander la permission du microphone
      var statusMic = await Permission.microphone.status;
      if (!statusMic.isGranted) {
        statusMic = await Permission.microphone.request();
      }

      // Sur Android 13+, on n'a plus besoin de permission storage pour les fichiers temporaires
      // Mais on demande quand m√™me pour la compatibilit√©
      if (await Permission.storage.isDenied) {
        await Permission.storage.request();
      }

      return statusMic.isGranted;
    } catch (e) {
      print("Erreur lors de la demande de permissions: $e");
      return false;
    }
  }

  void _startRecording() async {
    try {
      // Demander les permissions
      bool granted = await requestPermissions();
      if (!granted) {
        // Ne pas afficher de SnackBar pour √©viter les probl√®mes de contexte
        print("Permission microphone non accord√©e !");
        return;
      }

      // Obtenir le r√©pertoire temporaire
      final tempDir = await getTemporaryDirectory();
      final timestamp = DateTime.now().millisecondsSinceEpoch;
      final path = '${tempDir.path}/audio_question_$timestamp.aac';

      // Initialiser le recorder s'il n'est pas d√©j√† initialis√©
      if (!_recorderInitialized) {
        try {
          // S'assurer que le recorder est compl√®tement ferm√© avant de l'ouvrir
          try {
            await _recorder.closeRecorder();
            await Future.delayed(const Duration(milliseconds: 100));
          } catch (_) {
            // Ignorer si d√©j√† ferm√©
          }
          
          await _recorder.openRecorder();
          _recorderInitialized = true;
          print('‚úÖ [VoiceChatPage] Recorder initialis√©');
        } catch (e) {
          print('‚ùå [VoiceChatPage] Erreur lors de l\'initialisation du recorder: $e');
          // Essayer une fois de plus avec un d√©lai plus long
          try {
            await Future.delayed(const Duration(milliseconds: 300));
            await _recorder.closeRecorder();
            await Future.delayed(const Duration(milliseconds: 200));
            await _recorder.openRecorder();
            _recorderInitialized = true;
            print('‚úÖ [VoiceChatPage] Recorder initialis√© apr√®s retry');
          } catch (e2) {
            print('‚ùå [VoiceChatPage] Erreur lors du retry d\'initialisation: $e2');
            rethrow;
          }
        }
      }

      // V√©rifier si le recorder est d√©j√† en train d'enregistrer et l'arr√™ter si n√©cessaire
      try {
        bool isCurrentlyRecording = await _recorder.isRecording;
        if (isCurrentlyRecording) {
          print('‚ö†Ô∏è [VoiceChatPage] Le recorder est d√©j√† en train d\'enregistrer, arr√™t du pr√©c√©dent...');
          try {
            await _recorder.stopRecorder();
            await Future.delayed(const Duration(milliseconds: 200)); // Attendre un peu plus
            print('‚úÖ [VoiceChatPage] Enregistrement pr√©c√©dent arr√™t√©');
          } catch (e) {
            print('‚ö†Ô∏è [VoiceChatPage] Erreur lors de l\'arr√™t du recorder pr√©c√©dent: $e');
            // Continuer quand m√™me
          }
        }
      } catch (e) {
        print('‚ö†Ô∏è [VoiceChatPage] Erreur lors de la v√©rification isRecording: $e');
        // Continuer quand m√™me
      }

      // D√©marrer l'enregistrement
      try {
        await _recorder.startRecorder(
          toFile: path,
          codec: Codec.aacADTS,
        );
        print('‚úÖ [VoiceChatPage] Enregistrement d√©marr√©: $path');
      } catch (e) {
        print('‚ùå [VoiceChatPage] Erreur lors du d√©marrage de l\'enregistrement: $e');
        // Si le d√©marrage √©choue, essayer de r√©initialiser compl√®tement le recorder
        try {
          print('üîÑ [VoiceChatPage] Tentative de r√©initialisation compl√®te...');
          // Fermer compl√®tement
          try {
            if (await _recorder.isRecording) {
              await _recorder.stopRecorder();
            }
          } catch (_) {
            // Ignorer
          }
          
          try {
            await _recorder.closeRecorder();
          } catch (_) {
            // Ignorer si d√©j√† ferm√©
          }
          
          _recorderInitialized = false;
          await Future.delayed(const Duration(milliseconds: 300));
          
          // Rouvrir
          await _recorder.openRecorder();
          _recorderInitialized = true;
          
          await Future.delayed(const Duration(milliseconds: 100));
          
          // R√©essayer de d√©marrer
          await _recorder.startRecorder(
            toFile: path,
            codec: Codec.aacADTS,
          );
          print('‚úÖ [VoiceChatPage] Enregistrement d√©marr√© apr√®s r√©initialisation compl√®te');
        } catch (e2) {
          print('‚ùå [VoiceChatPage] Erreur lors de la r√©initialisation compl√®te: $e2');
          _recorderInitialized = false;
          rethrow;
        }
      }

      // Mettre √† jour l'√©tat
      if (mounted) {
        setState(() {
          _isRecording = true;
          _isListening = true;
        });
        _pulseController.repeat(reverse: true);
        _waveController.repeat();
      }
    } catch (e) {
      print("Erreur lors du d√©marrage de l'enregistrement: $e");
      if (mounted) {
        setState(() {
          _isRecording = false;
          _isListening = false;
        });
      }
    }
  }


  Future<File> stopRecording() async {
    try {
      // V√©rifier que le recorder est initialis√©
      if (!_recorderInitialized) {
        print('‚ùå [VoiceChatPage] Le recorder n\'est pas initialis√©');
        throw Exception('Le recorder n\'est pas initialis√©');
      }

      // Essayer d'arr√™ter l'enregistrement, m√™me si isRecording retourne false
      // (car cette v√©rification peut √™tre peu fiable)
      String? path;
      try {
        // V√©rifier d'abord si le recorder est en train d'enregistrer
        bool isCurrentlyRecording = await _recorder.isRecording;
        print('üìä [VoiceChatPage] √âtat du recorder (isRecording): $isCurrentlyRecording');
        
        if (isCurrentlyRecording) {
          path = await _recorder.stopRecorder();
        } else {
          // Si isRecording retourne false mais qu'on pense qu'on enregistre,
          // on essaie quand m√™me d'arr√™ter (au cas o√π)
          print('‚ö†Ô∏è [VoiceChatPage] isRecording=false mais on essaie quand m√™me d\'arr√™ter...');
          try {
            path = await _recorder.stopRecorder();
          } catch (e) {
            print('‚ö†Ô∏è [VoiceChatPage] Erreur lors de l\'arr√™t (normal si pas d\'enregistrement): $e');
            throw Exception('Aucun enregistrement en cours');
          }
        }
      } catch (e) {
        print('‚ùå [VoiceChatPage] Erreur lors de stopRecorder: $e');
        rethrow;
      }
      
      // V√©rifier que le path n'est pas null ou vide
      if (path == null || path.isEmpty) {
        throw Exception('Le chemin du fichier audio est vide');
      }
      
      print('‚úÖ [VoiceChatPage] Enregistrement arr√™t√©: $path');

      // Attendre un peu plus longtemps pour que le fichier soit compl√®tement √©crit
      await Future.delayed(const Duration(milliseconds: 300));

      // Cr√©er l'objet File et v√©rifier qu'il existe
      File audioFile = File(path);
      
      // Attendre jusqu'√† ce que le fichier existe (avec timeout)
      int attempts = 0;
      while (!await audioFile.exists() && attempts < 10) {
        await Future.delayed(const Duration(milliseconds: 100));
        attempts++;
      }
      
      if (!await audioFile.exists()) {
        throw Exception('Le fichier audio n\'existe pas au chemin: $path');
      }

      // V√©rifier que le fichier n'est pas vide
      int fileSize = 0;
      attempts = 0;
      while (fileSize == 0 && attempts < 10) {
        fileSize = await audioFile.length();
        if (fileSize == 0) {
          await Future.delayed(const Duration(milliseconds: 100));
          attempts++;
        }
      }
      
      if (fileSize == 0) {
        throw Exception('Le fichier audio est vide. Assurez-vous d\'avoir parl√© pendant l\'enregistrement.');
      }

      // Fermer le recorder proprement apr√®s l'enregistrement
      // On le rouvrira au prochain enregistrement
      try {
        // Attendre un peu avant de fermer pour s'assurer que tout est √©crit
        await Future.delayed(const Duration(milliseconds: 100));
        await _recorder.closeRecorder();
        _recorderInitialized = false;
        print('‚úÖ [VoiceChatPage] Recorder ferm√© proprement');
      } catch (e) {
        print('‚ö†Ô∏è [VoiceChatPage] Erreur lors de la fermeture du recorder: $e');
        // R√©initialiser le flag m√™me en cas d'erreur
        _recorderInitialized = false;
      }

      return audioFile;
    } catch (e) {
      print('‚ùå [VoiceChatPage] Erreur dans stopRecording: $e');
      // En cas d'erreur, on essaie de nettoyer le recorder
      try {
        // Essayer d'arr√™ter si en cours
        try {
          if (await _recorder.isRecording) {
            await _recorder.stopRecorder();
          }
        } catch (_) {
          // Ignorer
        }
        // Fermer le recorder pour le r√©initialiser
        if (_recorderInitialized) {
          await _recorder.closeRecorder();
          _recorderInitialized = false;
          print('‚úÖ [VoiceChatPage] Recorder ferm√© apr√®s erreur');
        }
      } catch (_) {
        // Ignorer les erreurs de nettoyage
        _recorderInitialized = false; // R√©initialiser le flag quand m√™me
      }
      rethrow;
    }
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: Colors.grey[50],
      appBar: AppBar(
        elevation: 0,
        backgroundColor: const Color(0xFF4DD0E1),
        title: Row(
          children: [
            Container(
              padding: const EdgeInsets.all(8),
              decoration: const BoxDecoration(
                color: Colors.white,
                shape: BoxShape.circle,
              ),
              child: const Icon(
                Icons.account_balance_wallet,
                color: Color(0xFF4DD0E1),
                size: 24,
              ),
            ),
            const SizedBox(width: 12),
            const Expanded(
              child: Column(
                crossAxisAlignment: CrossAxisAlignment.start,
                children: [
                  Text(
                    'Assistant Financier',
                    style: TextStyle(
                      fontSize: 18,
                      fontWeight: FontWeight.bold,
                      color: Colors.white,
                    ),
                  ),
                  Text(
                    'En ligne',
                    style: TextStyle(
                      fontSize: 12,
                      color: Colors.white70,
                    ),
                  ),
                ],
              ),
            ),
          ],
        ),
        actions: [
          PopupMenuButton<String>(
            icon: const Icon(Icons.more_vert, color: Colors.white),
            onSelected: (value) {
              if (value == 'logout') {
                _logout();
              }
            },
            itemBuilder: (BuildContext context) => [
              const PopupMenuItem<String>(
                value: 'logout',
                child: Row(
                  children: [
                    Icon(Icons.logout, color: Colors.red),
                    SizedBox(width: 8),
                    Text('D√©connexion'),
                  ],
                ),
              ),
            ],
          ),
        ],
      ),
      body: Column(
        children: [
          // Zone de messages
          Expanded(
            child: ListView.builder(
              controller: _scrollController,
              padding: const EdgeInsets.all(16),
              itemCount: _messages.length + (_isTyping ? 1 : 0),
              itemBuilder: (context, index) {
                if (index == _messages.length && _isTyping) {
                  return _buildTypingIndicator();
                }

                final message = _messages[index];
                return _buildMessageBubble(message);
              },
            ),
          ),

          // Indicateur d'√©coute
          if (_isListening)
            Container(
              padding: const EdgeInsets.symmetric(vertical: 12),
              child: Row(
                mainAxisAlignment: MainAxisAlignment.center,
                children: [
                  _buildWaveBar(0),
                  const SizedBox(width: 4),
                  _buildWaveBar(1),
                  const SizedBox(width: 4),
                  _buildWaveBar(2),
                  const SizedBox(width: 4),
                  _buildWaveBar(3),
                  const SizedBox(width: 4),
                  _buildWaveBar(4),
                  const SizedBox(width: 12),
                  const Text(
                    '√âcoute en cours...',
                    style: TextStyle(
                      color: Color(0xFF4DD0E1),
                      fontWeight: FontWeight.w500,
                    ),
                  ),
                ],
              ),
            ),

          // Zone de saisie
          Container(
            padding: const EdgeInsets.all(16),
            decoration: BoxDecoration(
              color: Colors.white,
              boxShadow: [
                BoxShadow(
                  color: Colors.black.withOpacity(0.05),
                  blurRadius: 10,
                  offset: const Offset(0, -5),
                ),
              ],
            ),
            child: Row(
              children: [
                // Bouton vocal avec support pour press-and-hold et tap
                GestureDetector(
                  onTapDown: (_) {
                    if (!_isRecording) {
                      _startRecording();
                    }
                  },
                  onTapUp: (_) {
                    if (_isRecording) {
                      _handleStopRecordingAndSend();
                    }
                  },
                  onTapCancel: () {
                    if (_isRecording) {
                      _handleStopRecordingAndSend();
                    }
                  },
                  child: AnimatedBuilder(
                    animation: _pulseAnimation,
                    builder: (context, child) {
                      return Transform.scale(
                        scale: _isRecording ? _pulseAnimation.value : 1.0,
                        child: Container(
                          width: 56,
                          height: 56,
                          decoration: BoxDecoration(
                            color: _isRecording
                                ? Colors.red
                                : const Color(0xFF4DD0E1),
                            shape: BoxShape.circle,
                            boxShadow: [
                              BoxShadow(
                                color: (_isRecording ? Colors.red : const Color(0xFF4DD0E1))
                                    .withOpacity(0.3),
                                blurRadius: _isRecording ? 20 : 10,
                                spreadRadius: _isRecording ? 5 : 2,
                              ),
                            ],
                          ),
                          child: Icon(
                            _isRecording ? Icons.mic : Icons.mic_none,
                            color: Colors.white,
                            size: 28,
                          ),
                        ),
                      );
                    },
                  ),
                ),
                const SizedBox(width: 12),

                // Champ de texte
                Expanded(
                  child: Container(
                    decoration: BoxDecoration(
                      color: Colors.grey[100],
                      borderRadius: BorderRadius.circular(24),
                    ),
                    child: TextField(
                      controller: _textController,
                      decoration: InputDecoration(
                        hintText: 'Tapez votre message...',
                        border: InputBorder.none,
                        contentPadding: const EdgeInsets.symmetric(
                          horizontal: 20,
                          vertical: 12,
                        ),
                        suffixIcon: IconButton(
                          icon: const Icon(Icons.attach_file),
                          onPressed: () {},
                          color: Colors.grey[600],
                        ),
                      ),
                      maxLines: null,
                      textInputAction: TextInputAction.send,
                      onSubmitted: (_) => _handleTextMessage(),
                    ),
                  ),
                ),
                const SizedBox(width: 8),

                // Bouton d'envoi
                Container(
                  width: 48,
                  height: 48,
                  decoration: BoxDecoration(
                    color: const Color(0xFF4DD0E1),
                    shape: BoxShape.circle,
                  ),
                  child: IconButton(
                    icon: const Icon(Icons.send, color: Colors.white),
                    onPressed: _handleTextMessage,
                  ),
                ),
              ],
            ),
          ),
        ],
      ),
    );
  }

  Widget _buildMessageBubble(Message message) {
    final messageId = message.timestamp.millisecondsSinceEpoch.toString();
    final isCurrentlyPlaying = _currentlyPlayingMessageId == messageId && _isPlaying;
    
    return Padding(
      padding: const EdgeInsets.only(bottom: 12),
      child: Row(
        mainAxisAlignment: message.isUser
            ? MainAxisAlignment.end
            : MainAxisAlignment.start,
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          if (!message.isUser) ...[
            Container(
              width: 36,
              height: 36,
              decoration: BoxDecoration(
                color: const Color(0xFF4DD0E1),
                shape: BoxShape.circle,
              ),
              child: const Icon(
                Icons.smart_toy,
                color: Colors.white,
                size: 20,
              ),
            ),
            const SizedBox(width: 8),
          ],
          Flexible(
            child: Column(
              crossAxisAlignment: message.isUser
                  ? CrossAxisAlignment.end
                  : CrossAxisAlignment.start,
              children: [
                Container(
                  padding: const EdgeInsets.symmetric(
                    horizontal: 16,
                    vertical: 12,
                  ),
                  decoration: BoxDecoration(
                    color: message.isUser
                        ? const Color(0xFF4DD0E1)
                        : Colors.white,
                    borderRadius: BorderRadius.only(
                      topLeft: const Radius.circular(20),
                      topRight: const Radius.circular(20),
                      bottomLeft: Radius.circular(message.isUser ? 20 : 4),
                      bottomRight: Radius.circular(message.isUser ? 4 : 20),
                    ),
                    boxShadow: [
                      BoxShadow(
                        color: Colors.black.withOpacity(0.05),
                        blurRadius: 5,
                        offset: const Offset(0, 2),
                      ),
                    ],
                  ),
                  child: message.isAudio && ((message.audioBase64 != null && !message.isUser) || (message.audioFilePath != null && message.isUser))
                      ? Row(
                          mainAxisSize: MainAxisSize.min,
                          children: [
                            IconButton(
                              icon: Icon(
                                isCurrentlyPlaying ? Icons.pause : Icons.play_arrow,
                                color: message.isUser ? Colors.white : const Color(0xFF4DD0E1),
                                size: 28,
                              ),
                              onPressed: () {
                                if (message.isUser && message.audioFilePath != null) {
                                  _playAudioFromFile(message.audioFilePath!, _messages.indexOf(message));
                                } else if (!message.isUser && message.audioBase64 != null) {
                                  _playAudioFromBase64(message.audioBase64!, _messages.indexOf(message));
                                }
                              },
                            ),
                            const SizedBox(width: 8),
                            Text(
                              isCurrentlyPlaying ? "Lecture en cours..." : (message.isUser ? "Audio envoy√©" : "R√©ponse audio"),
                              style: TextStyle(
                                color: message.isUser ? Colors.white : Colors.black87,
                                fontSize: 15,
                              ),
                            ),
                          ],
                        )
                      : Text(
                          message.text,
                          style: TextStyle(
                            color: message.isUser ? Colors.white : Colors.black87,
                            fontSize: 15,
                          ),
                        ),
                ),
                const SizedBox(height: 4),
                Padding(
                  padding: const EdgeInsets.symmetric(horizontal: 8),
                  child: Text(
                    '${message.timestamp.hour}:${message.timestamp.minute.toString().padLeft(2, '0')}',
                    style: TextStyle(
                      fontSize: 11,
                      color: Colors.grey[500],
                    ),
                  ),
                ),
              ],
            ),
          ),
          if (message.isUser) ...[
            const SizedBox(width: 8),
            Container(
              width: 36,
              height: 36,
              decoration: BoxDecoration(
                color: Colors.grey[300],
                shape: BoxShape.circle,
              ),
              child: Icon(
                Icons.person,
                color: Colors.grey[600],
                size: 20,
              ),
            ),
          ],
        ],
      ),
    );
  }

  Future<void> _playAudioFromBase64(String audioBase64, int messageIndex) async {
    try {
      final messageId = _messages[messageIndex].timestamp.millisecondsSinceEpoch.toString();
      
      // Si c'est le m√™me message qui est en train de jouer, on arr√™te
      if (_isPlaying && _currentlyPlayingMessageId == messageId) {
        await _player.stopPlayer();
        if (mounted) {
          setState(() {
            _isPlaying = false;
            _currentlyPlayingMessageId = null;
          });
        }
        return;
      }
      
      // D√©coder le Base64
      final audioBytes = base64Decode(audioBase64);
      
      // Sauvegarder dans un fichier temporaire
      final tempDir = await getTemporaryDirectory();
      final audioFile = File('${tempDir.path}/response_audio_${DateTime.now().millisecondsSinceEpoch}.mp3');
      await audioFile.writeAsBytes(audioBytes);
      
      print('üéµ [VoiceChatPage] Audio sauvegard√©: ${audioFile.path} (${audioBytes.length} bytes)');
      
      // Initialiser le player si n√©cessaire
      if (!_playerInitialized) {
        await _player.openPlayer();
        _playerInitialized = true;
      }
      
      // Arr√™ter la lecture pr√©c√©dente si elle est en cours
      if (_isPlaying) {
        await _player.stopPlayer();
      }
      
      // Mettre √† jour l'√©tat pour afficher l'indicateur de lecture
      setState(() {
        _isPlaying = true;
        _currentlyPlayingMessageId = messageId;
      });
      
      // Jouer l'audio
      await _player.startPlayer(
        fromURI: audioFile.path,
        codec: Codec.mp3,
        whenFinished: () {
          if (mounted) {
            setState(() {
              _isPlaying = false;
              _currentlyPlayingMessageId = null;
            });
          }
          // Nettoyer le fichier temporaire apr√®s la lecture
          audioFile.delete();
        },
      );
      
    } catch (e) {
      print('‚ùå [VoiceChatPage] Erreur lors de la lecture audio: $e');
      if (mounted) {
        setState(() {
          _isPlaying = false;
          _currentlyPlayingMessageId = null;
        });
      }
    }
  }

  Future<void> _playAudioFromFile(String audioFilePath, int messageIndex) async {
    try {
      final messageId = _messages[messageIndex].timestamp.millisecondsSinceEpoch.toString();
      
      // Si c'est le m√™me message qui est en train de jouer, on arr√™te
      if (_isPlaying && _currentlyPlayingMessageId == messageId) {
        await _player.stopPlayer();
        if (mounted) {
          setState(() {
            _isPlaying = false;
            _currentlyPlayingMessageId = null;
          });
        }
        return;
      }
      
      // V√©rifier que le fichier existe
      final audioFile = File(audioFilePath);
      if (!await audioFile.exists()) {
        print('‚ùå [VoiceChatPage] Le fichier audio n\'existe pas: $audioFilePath');
        return;
      }
      
      print('üéµ [VoiceChatPage] Lecture de l\'audio: ${audioFile.path}');
      
      // Initialiser le player si n√©cessaire
      if (!_playerInitialized) {
        await _player.openPlayer();
        _playerInitialized = true;
      }
      
      // Arr√™ter la lecture pr√©c√©dente si elle est en cours
      if (_isPlaying) {
        await _player.stopPlayer();
      }
      
      // Mettre √† jour l'√©tat pour afficher l'indicateur de lecture
      setState(() {
        _isPlaying = true;
        _currentlyPlayingMessageId = messageId;
      });
      
      // Jouer l'audio (AAC depuis l'utilisateur)
      await _player.startPlayer(
        fromURI: audioFile.path,
        codec: Codec.aacADTS, // Utiliser AAC pour les enregistrements de l'utilisateur
        whenFinished: () {
          if (mounted) {
            setState(() {
              _isPlaying = false;
              _currentlyPlayingMessageId = null;
            });
          }
        },
      );
      
    } catch (e) {
      print('‚ùå [VoiceChatPage] Erreur lors de la lecture audio depuis fichier: $e');
      if (mounted) {
        setState(() {
          _isPlaying = false;
          _currentlyPlayingMessageId = null;
        });
      }
    }
  }

  Widget _buildTypingIndicator() {
    return Padding(
      padding: const EdgeInsets.only(bottom: 12),
      child: Row(
        children: [
          Container(
            width: 36,
            height: 36,
            decoration: BoxDecoration(
              color: const Color(0xFF4DD0E1),
              shape: BoxShape.circle,
            ),
            child: const Icon(
              Icons.smart_toy,
              color: Colors.white,
              size: 20,
            ),
          ),
          const SizedBox(width: 8),
          Container(
            padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 12),
            decoration: BoxDecoration(
              color: Colors.white,
              borderRadius: BorderRadius.circular(20),
              boxShadow: [
                BoxShadow(
                  color: Colors.black.withOpacity(0.05),
                  blurRadius: 5,
                  offset: const Offset(0, 2),
                ),
              ],
            ),
            child: Row(
              mainAxisSize: MainAxisSize.min,
              children: [
                _buildDot(0),
                const SizedBox(width: 4),
                _buildDot(1),
                const SizedBox(width: 4),
                _buildDot(2),
              ],
            ),
          ),
        ],
      ),
    );
  }

  Widget _buildDot(int index) {
    return TweenAnimationBuilder<double>(
      tween: Tween(begin: 0.0, end: 1.0),
      duration: const Duration(milliseconds: 600),
      builder: (context, value, child) {
        final delay = index * 0.2;
        final animValue = ((value + delay) % 1.0);
        final opacity = (animValue < 0.5)
            ? animValue * 2
            : (1 - animValue) * 2;

        return Opacity(
          opacity: opacity,
          child: Container(
            width: 8,
            height: 8,
            decoration: BoxDecoration(
              color: Colors.grey[400],
              shape: BoxShape.circle,
            ),
          ),
        );
      },
      onEnd: () {
        if (_isTyping && mounted) {
          setState(() {});
        }
      },
    );
  }

  Widget _buildWaveBar(int index) {
    return AnimatedBuilder(
      animation: _waveController,
      builder: (context, child) {
        final delay = index * 0.1;
        final animValue = (_waveController.value + delay) % 1.0;
        final height = 4 + (20 * (0.5 - (animValue - 0.5).abs()) * 2);

        return Container(
          width: 4,
          height: height,
          decoration: BoxDecoration(
            color: const Color(0xFF4DD0E1),
            borderRadius: BorderRadius.circular(2),
          ),
        );
      },
    );
  }
}